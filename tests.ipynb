{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-probability nb_black gin-config\n",
    "# !pip install torch==1.8.0+cpu torchvision==0.9.0+cpu torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import tensorflow as tf\\nimport perturbations\\n\\ndef argmax(x, axis=-1):\\n    return tf.one_hot(tf.argmax(x, axis=axis), tf.shape(x)[axis])\";\n",
       "                var nbb_formatted_code = \"import tensorflow as tf\\nimport perturbations\\n\\n\\ndef argmax(x, axis=-1):\\n    return tf.one_hot(tf.argmax(x, axis=axis), tf.shape(x)[axis])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import perturbations\n",
    "\n",
    "def argmax(x, axis=-1):\n",
    "    return tf.one_hot(tf.argmax(x, axis=axis), tf.shape(x)[axis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"argmax(tf.constant([-0.6, 1.9, -0.2, 1.1, -1.0], dtype=tf.float32))\";\n",
       "                var nbb_formatted_code = \"argmax(tf.constant([-0.6, 1.9, -0.2, 1.1, -1.0], dtype=tf.float32))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "argmax(tf.constant([-0.6, 1.9, -0.2, 1.1, -1.0], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"from perturbations import perturbations\";\n",
       "                var nbb_formatted_code = \"from perturbations import perturbations\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from perturbations import perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"pert_argmax_fn = perturbations.perturbed(argmax,\\n                                      num_samples=1000000,\\n                                      sigma=0.5,\\n                                      noise='gumbel',\\n                                      batched=False)\";\n",
       "                var nbb_formatted_code = \"pert_argmax_fn = perturbations.perturbed(\\n    argmax, num_samples=1000000, sigma=0.5, noise=\\\"gumbel\\\", batched=False\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pert_argmax_fn = perturbations.perturbed(argmax,\n",
    "                                      num_samples=1000000,\n",
    "                                      sigma=0.5,\n",
    "                                      noise='gumbel',\n",
    "                                      batched=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0.00546 , 0.815495, 0.01207 , 0.16443 , 0.002545], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"theta = tf.constant([-0.6, 1.9, -0.2, 1.1, -1.0], dtype=tf.float32)\\npert_argmax_fn(theta)\";\n",
       "                var nbb_formatted_code = \"theta = tf.constant([-0.6, 1.9, -0.2, 1.1, -1.0], dtype=tf.float32)\\npert_argmax_fn(theta)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta = tf.constant([-0.6, 1.9, -0.2, 1.1, -1.0], dtype=tf.float32)\n",
    "pert_argmax_fn(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([0.00549293, 0.8152234 , 0.01222475, 0.16459078, 0.00246813],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"sigma = 0.5\\ntf.nn.softmax(theta / sigma)\";\n",
       "                var nbb_formatted_code = \"sigma = 0.5\\ntf.nn.softmax(theta / sigma)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigma = 0.5\n",
    "tf.nn.softmax(theta / sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "Good!\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# coding=utf-8\\n# Copyright 2021 The Google Research Authors.\\n#\\n# Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\\n# you may not use this file except in compliance with the License.\\n# You may obtain a copy of the License at\\n#\\n#     http://www.apache.org/licenses/LICENSE-2.0\\n#\\n# Unless required by applicable law or agreed to in writing, software\\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n# See the License for the specific language governing permissions and\\n# limitations under the License.\\n\\n# Lint as: python3\\n\\\"\\\"\\\"Tests for the fenchel_young module.\\\"\\\"\\\"\\n\\nimport tensorflow.compat.v2 as tf\\n\\nfrom perturbations import fenchel_young as fy\\n\\n\\ndef ranks(inputs, axis=-1):\\n    \\\"\\\"\\\"Returns the ranks of the input values among the given axis.\\\"\\\"\\\"\\n    return 1 + tf.cast(\\n        tf.argsort(tf.argsort(inputs, axis=axis), axis=axis),\\n        dtype=inputs.dtype,\\n    )\\n\\n\\nclass FenchelYoungTest(tf.test.TestCase):\\n    \\\"\\\"\\\"Testing the gradients obtained by the FenchelYoungLoss class.\\\"\\\"\\\"\\n\\n    def test_gradients(self):\\n        loss_fn = fy.FenchelYoungLoss(\\n            ranks, num_samples=10000, sigma=0.1, batched=False\\n        )\\n\\n        theta = tf.constant([1, 20, 7.3, 7.35])\\n        y_true = tf.constant([1, 4, 3, 2], dtype=theta.dtype)\\n        y_hard_minimum = tf.constant([1, 4, 2, 3], dtype=theta.dtype)\\n        y_perturbed_minimum = tf.constant(loss_fn.perturbed(theta))\\n\\n        with tf.GradientTape(persistent=True) as tape:\\n            tape.watch(theta)\\n            g_true = tape.gradient(loss_fn(y_true, theta), theta)\\n            g_hard_minimum = tape.gradient(\\n                loss_fn(y_hard_minimum, theta), theta\\n            )\\n            g_perturbed_minimum = tape.gradient(\\n                loss_fn(y_perturbed_minimum, theta), theta\\n            )\\n\\n        # The gradient should be close to zero for the two first values.\\n        self.assertAllClose(g_true[:2], [0.0, 0.0])\\n        self.assertLess(tf.norm(g_perturbed_minimum), tf.norm(g_hard_minimum))\\n        self.assertLess(tf.norm(g_hard_minimum), tf.norm(g_true))\\n        for g in [g_true, g_hard_minimum, g_perturbed_minimum]:\\n            self.assertAllClose(tf.math.reduce_sum(g), 0.0)\\n        print(\\\"Good!\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    tf.enable_v2_behavior()\\n    FenchelYoungTest().test_gradients()\";\n",
       "                var nbb_formatted_code = \"# coding=utf-8\\n# Copyright 2021 The Google Research Authors.\\n#\\n# Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\\n# you may not use this file except in compliance with the License.\\n# You may obtain a copy of the License at\\n#\\n#     http://www.apache.org/licenses/LICENSE-2.0\\n#\\n# Unless required by applicable law or agreed to in writing, software\\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n# See the License for the specific language governing permissions and\\n# limitations under the License.\\n\\n# Lint as: python3\\n\\\"\\\"\\\"Tests for the fenchel_young module.\\\"\\\"\\\"\\n\\nimport tensorflow.compat.v2 as tf\\n\\nfrom perturbations import fenchel_young as fy\\n\\n\\ndef ranks(inputs, axis=-1):\\n    \\\"\\\"\\\"Returns the ranks of the input values among the given axis.\\\"\\\"\\\"\\n    return 1 + tf.cast(\\n        tf.argsort(tf.argsort(inputs, axis=axis), axis=axis),\\n        dtype=inputs.dtype,\\n    )\\n\\n\\nclass FenchelYoungTest(tf.test.TestCase):\\n    \\\"\\\"\\\"Testing the gradients obtained by the FenchelYoungLoss class.\\\"\\\"\\\"\\n\\n    def test_gradients(self):\\n        loss_fn = fy.FenchelYoungLoss(\\n            ranks, num_samples=10000, sigma=0.1, batched=False\\n        )\\n\\n        theta = tf.constant([1, 20, 7.3, 7.35])\\n        y_true = tf.constant([1, 4, 3, 2], dtype=theta.dtype)\\n        y_hard_minimum = tf.constant([1, 4, 2, 3], dtype=theta.dtype)\\n        y_perturbed_minimum = tf.constant(loss_fn.perturbed(theta))\\n\\n        with tf.GradientTape(persistent=True) as tape:\\n            tape.watch(theta)\\n            g_true = tape.gradient(loss_fn(y_true, theta), theta)\\n            g_hard_minimum = tape.gradient(loss_fn(y_hard_minimum, theta), theta)\\n            g_perturbed_minimum = tape.gradient(\\n                loss_fn(y_perturbed_minimum, theta), theta\\n            )\\n\\n        # The gradient should be close to zero for the two first values.\\n        self.assertAllClose(g_true[:2], [0.0, 0.0])\\n        self.assertLess(tf.norm(g_perturbed_minimum), tf.norm(g_hard_minimum))\\n        self.assertLess(tf.norm(g_hard_minimum), tf.norm(g_true))\\n        for g in [g_true, g_hard_minimum, g_perturbed_minimum]:\\n            self.assertAllClose(tf.math.reduce_sum(g), 0.0)\\n        print(\\\"Good!\\\")\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    tf.enable_v2_behavior()\\n    FenchelYoungTest().test_gradients()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2021 The Google Research Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Lint as: python3\n",
    "\"\"\"Tests for the fenchel_young module.\"\"\"\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "\n",
    "from perturbations import fenchel_young as fy\n",
    "\n",
    "\n",
    "def ranks(inputs, axis=-1):\n",
    "    \"\"\"Returns the ranks of the input values among the given axis.\"\"\"\n",
    "    return 1 + tf.cast(\n",
    "        tf.argsort(tf.argsort(inputs, axis=axis), axis=axis),\n",
    "        dtype=inputs.dtype,\n",
    "    )\n",
    "\n",
    "\n",
    "class FenchelYoungTest(tf.test.TestCase):\n",
    "    \"\"\"Testing the gradients obtained by the FenchelYoungLoss class.\"\"\"\n",
    "\n",
    "    def test_gradients(self):\n",
    "        loss_fn = fy.FenchelYoungLoss(\n",
    "            ranks, num_samples=10000, sigma=0.1, batched=False\n",
    "        )\n",
    "\n",
    "        theta = tf.constant([1, 20, 7.3, 7.35])\n",
    "        y_true = tf.constant([1, 4, 3, 2], dtype=theta.dtype)\n",
    "        y_hard_minimum = tf.constant([1, 4, 2, 3], dtype=theta.dtype)\n",
    "        y_perturbed_minimum = tf.constant(loss_fn.perturbed(theta))\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(theta)\n",
    "            g_true = tape.gradient(loss_fn(y_true, theta), theta)\n",
    "            g_hard_minimum = tape.gradient(\n",
    "                loss_fn(y_hard_minimum, theta), theta\n",
    "            )\n",
    "            g_perturbed_minimum = tape.gradient(\n",
    "                loss_fn(y_perturbed_minimum, theta), theta\n",
    "            )\n",
    "\n",
    "        # The gradient should be close to zero for the two first values.\n",
    "        self.assertAllClose(g_true[:2], [0.0, 0.0])\n",
    "        self.assertLess(tf.norm(g_perturbed_minimum), tf.norm(g_hard_minimum))\n",
    "        self.assertLess(tf.norm(g_hard_minimum), tf.norm(g_true))\n",
    "        for g in [g_true, g_hard_minimum, g_perturbed_minimum]:\n",
    "            self.assertAllClose(tf.math.reduce_sum(g), 0.0)\n",
    "        print(\"Good!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.enable_v2_behavior()\n",
    "    FenchelYoungTest().test_gradients()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"from torch.distributions.gumbel import Gumbel\\nimport matplotlib.pyplot as plt\\nimport tensorflow_probability as tfp\\nimport numpy as np\";\n",
       "                var nbb_formatted_code = \"from torch.distributions.gumbel import Gumbel\\nimport matplotlib.pyplot as plt\\nimport tensorflow_probability as tfp\\nimport numpy as np\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.distributions.gumbel import Gumbel\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"shape = [1000]\";\n",
       "                var nbb_formatted_code = \"shape = [1000]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shape = [1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOlklEQVR4nO3df6zddX3H8edLQFzUWRx3TdfWXaLdTF1GMTcMw7IwmZMfxmqyEUiGnSOpS3DBxGQr7g9dMhLMJmxmjqQKs25MJKChEeZEZDH+wY9bZUBbmXdY0jaFXhUQZ6YpvvfH/TIP5faec++5t+f04/ORnNzv9/39fM/3fb+hL773c77nnFQVkqS2vGzUDUiSlp/hLkkNMtwlqUGGuyQ1yHCXpAadPOoGAE4//fSanJwcdRuSdELZtWvXd6tqYr5tYxHuk5OTTE9Pj7oNSTqhJHniWNuclpGkBhnuktQgw12SGmS4S1KDDHdJapDhLkkN6hvuSV6R5IEk/5lkd5K/6upnJLk/yUySzyV5eVc/tVuf6bZPrvDvIEk6yiBX7j8G3lpVZwKbgAuSnAN8FLi+qt4APA1c0Y2/Ani6q1/fjZMkHUd9w73m/LBbPaV7FPBW4LauvgN4V7e8uVun235+kixXw5Kk/gZ6h2qSk4BdwBuATwD/DTxTVUe6IQeAtd3yWmA/QFUdSfIs8EvAd496zq3AVoDXve51w/0WP2cmt905smPvu/bikR1b0uAGekG1qp6vqk3AOuBs4I3DHriqtlfVVFVNTUzM+9EIkqQlWtTdMlX1DHAv8BZgVZIXrvzXAQe75YPAeoBu+2uA7y1Hs5KkwQxyt8xEklXd8i8AbwP2Mhfyf9AN2wLc0S3v7Nbptn+1/KJWSTquBplzXwPs6ObdXwbcWlVfTLIHuCXJXwPfBG7sxt8I/HOSGeD7wKUr0LckaQF9w72qHgbOmqf+OHPz70fX/xf4w2XpTpK0JL5DVZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoP6hnuS9UnuTbInye4kV3X1jyQ5mOSh7nFRzz5XJ5lJ8liSt6/kLyBJeqmTBxhzBPhgVX0jyauBXUnu7rZdX1V/2zs4yUbgUuBNwK8AX0nya1X1/HI2Lkk6tr5X7lV1qKq+0S0/B+wF1i6wy2bglqr6cVV9B5gBzl6OZiVJg1nUnHuSSeAs4P6u9P4kDye5KclpXW0tsL9ntwPM8z+DJFuTTCeZnp2dXXznkqRjGjjck7wKuB34QFX9ALgBeD2wCTgEfGwxB66q7VU1VVVTExMTi9lVktTHQOGe5BTmgv3mqvo8QFU9VVXPV9VPgU/ys6mXg8D6nt3XdTVJ0nEyyN0yAW4E9lbVdT31NT3D3g082i3vBC5NcmqSM4ANwAPL17IkqZ9B7pY5F7gceCTJQ13tQ8BlSTYBBewD3gdQVbuT3ArsYe5Omyu9U0aSjq++4V5VXwcyz6a7FtjnGuCaIfqSJA3Bd6hKUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGjTIO1Sl/ze57c6RHHfftReP5LjSicord0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSg/qGe5L1Se5NsifJ7iRXdfXXJrk7ybe7n6d19ST5eJKZJA8nefNK/xKSpBcb5Mr9CPDBqtoInANcmWQjsA24p6o2APd06wAXAhu6x1bghmXvWpK0oL5fs1dVh4BD3fJzSfYCa4HNwHndsB3AfwB/0dU/U1UF3JdkVZI13fM0ZVRfOSdJ/Sxqzj3JJHAWcD+wuiewnwRWd8trgf09ux3oakc/19Yk00mmZ2dnF9u3JGkBA4d7klcBtwMfqKof9G7rrtJrMQeuqu1VNVVVUxMTE4vZVZLUx0DhnuQU5oL95qr6fFd+Ksmabvsa4HBXPwis79l9XVeTJB0ng9wtE+BGYG9VXdezaSewpVveAtzRU39Pd9fMOcCzLc63S9I46/uCKnAucDnwSJKHutqHgGuBW5NcATwBXNJtuwu4CJgBfgS8dzkbliT1N8jdMl8HcozN588zvoArh+xLkjQE36EqSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ3qG+5JbkpyOMmjPbWPJDmY5KHucVHPtquTzCR5LMnbV6pxSdKxDXLl/mnggnnq11fVpu5xF0CSjcClwJu6ff4xyUnL1awkaTB9w72qvgZ8f8Dn2wzcUlU/rqrvADPA2UP0J0lagmHm3N+f5OFu2ua0rrYW2N8z5kBXkyQdR0sN9xuA1wObgEPAxxb7BEm2JplOMj07O7vENiRJ81lSuFfVU1X1fFX9FPgkP5t6OQis7xm6rqvN9xzbq2qqqqYmJiaW0oYk6RiWFO5J1vSsvht44U6ancClSU5NcgawAXhguBYlSYt1cr8BST4LnAecnuQA8GHgvCSbgAL2Ae8DqKrdSW4F9gBHgCur6vkV6VySdEx9w72qLpunfOMC468BrhmmKUnScHyHqiQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNOnnUDUiDmNx258iOve/ai0d2bGmpvHKXpAYZ7pLUoL7hnuSmJIeTPNpTe22Su5N8u/t5WldPko8nmUnycJI3r2TzkqT5DXLl/mnggqNq24B7qmoDcE+3DnAhsKF7bAVuWJ42JUmL0Tfcq+prwPePKm8GdnTLO4B39dQ/U3PuA1YlWbNMvUqSBrTUOffVVXWoW34SWN0trwX294w70NVeIsnWJNNJpmdnZ5fYhiRpPkO/oFpVBdQS9tteVVNVNTUxMTFsG5KkHksN96demG7pfh7u6geB9T3j1nU1SdJxtNRw3wls6Za3AHf01N/T3TVzDvBsz/SNJOk46fsO1SSfBc4DTk9yAPgwcC1wa5IrgCeAS7rhdwEXATPAj4D3rkDPkqQ++oZ7VV12jE3nzzO2gCuHbUqSNBzfoSpJDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoJNH3YA07ia33TmS4+679uKRHFdt8MpdkhpkuEtSgwx3SWrQUHPuSfYBzwHPA0eqairJa4HPAZPAPuCSqnp6uDYlSYuxHFfuv1tVm6pqqlvfBtxTVRuAe7p1SdJxtBLTMpuBHd3yDuBdK3AMSdIChg33Ar6cZFeSrV1tdVUd6pafBFbPt2OSrUmmk0zPzs4O2YYkqdew97n/dlUdTPLLwN1JvtW7saoqSc23Y1VtB7YDTE1NzTtmEKO6B1mSxtlQV+5VdbD7eRj4AnA28FSSNQDdz8PDNilJWpwlh3uSVyZ59QvLwO8DjwI7gS3dsC3AHcM2KUlanGGmZVYDX0jywvP8a1V9KcmDwK1JrgCeAC4Zvk1J0mIsOdyr6nHgzHnq3wPOH6YpSdJwfIeqJDXIcJekBhnuktQgw12SGmS4S1KD/CYmaUz5DVAahlfuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CC/iUnSi4zqG6DAb4FaTl65S1KDDHdJatCKhXuSC5I8lmQmybaVOo4k6aVWZM49yUnAJ4C3AQeAB5PsrKo9K3E8SW0Y5Xz/qKzU6wwrdeV+NjBTVY9X1U+AW4DNK3QsSdJRVupumbXA/p71A8Bv9Q5IshXY2q3+MMljQxzvdOC7Q+zfMs/Nwjw/C/P8LGzo85OPDnX8Xz3WhpHdCllV24Hty/FcSaaramo5nqs1npuFeX4W5vlZ2Difn5WaljkIrO9ZX9fVJEnHwUqF+4PAhiRnJHk5cCmwc4WOJUk6yopMy1TVkSTvB/4dOAm4qap2r8SxOssyvdMoz83CPD8L8/wsbGzPT6pq1D1IkpaZ71CVpAYZ7pLUoCbCPcnfJPlWkoeTfCHJqlH3NA78CIhjS7I+yb1J9iTZneSqUfc0bpKclOSbSb446l7GTZJVSW7rcmdvkreMuqejNRHuwN3Ab1TVbwL/BVw94n5GrucjIC4ENgKXJdk42q7GyhHgg1W1ETgHuNLz8xJXAXtH3cSY+nvgS1X1RuBMxvA8NRHuVfXlqjrSrd7H3H31P+/8CIgFVNWhqvpGt/wcc/841462q/GRZB1wMfCpUfcybpK8Bvgd4EaAqvpJVT0z0qbm0US4H+VPgH8bdRNjYL6PgDC85pFkEjgLuH/ErYyTvwP+HPjpiPsYR2cAs8A/ddNWn0ryylE3dbQTJtyTfCXJo/M8NveM+Uvm/ty+eXSd6kSS5FXA7cAHquoHo+5nHCR5B3C4qnaNupcxdTLwZuCGqjoL+B9g7F7TOmG+Zq+qfm+h7Un+GHgHcH558z74ERB9JTmFuWC/uao+P+p+xsi5wDuTXAS8AvjFJP9SVX804r7GxQHgQFW98JfebYxhuJ8wV+4LSXIBc39CvrOqfjTqfsaEHwGxgCRhbs50b1VdN+p+xklVXV1V66pqkrn/br5qsP9MVT0J7E/y613pfGDsvqvihLly7+MfgFOBu+f+zXJfVf3paFsarRF8BMSJ5lzgcuCRJA91tQ9V1V2ja0knkD8Dbu4unB4H3jvifl7Cjx+QpAY1MS0jSXoxw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ16P8AaCGmaYV+0LIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"sampler = Gumbel(0.0, 1.0)\\nsamples_tch = sampler.sample(shape)\\nplt.hist(samples_tch.numpy(), bins=10)\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"sampler = Gumbel(0.0, 1.0)\\nsamples_tch = sampler.sample(shape)\\nplt.hist(samples_tch.numpy(), bins=10)\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampler = Gumbel(0.0, 1.0)\n",
    "samples_tch = sampler.sample(shape)\n",
    "plt.hist(samples_tch.numpy(), bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"sampler = tfp.distributions.Gumbel(0.0, 1.0)\\nsamples = sampler.sample(shape)\";\n",
       "                var nbb_formatted_code = \"sampler = tfp.distributions.Gumbel(0.0, 1.0)\\nsamples = sampler.sample(shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampler = tfp.distributions.Gumbel(0.0, 1.0)\n",
    "samples = sampler.sample(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"plt.hist(np.array(samples))\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"plt.hist(np.array(samples))\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.array(samples))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1657, -0.3990,  0.2303, -0.1693,  0.1969, -2.2686, -0.5040,  0.0511,\n",
      "         1.3192,  0.4267])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"import torch\\n\\nx = torch.randn([10])\\nprint(x)\\nx.long().type(torch.randn([1]).dtype)\";\n",
       "                var nbb_formatted_code = \"import torch\\n\\nx = torch.randn([10])\\nprint(x)\\nx.long().type(torch.randn([1]).dtype)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn([10])\n",
    "print(x)\n",
    "x.long().type(torch.randn([1]).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import functools\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "_GUMBEL = \"gumbel\"\n",
    "_NORMAL = \"normal\"\n",
    "SUPPORTED_NOISES = (_GUMBEL, _NORMAL)\n",
    "\n",
    "\n",
    "def sample_noise_with_gradients(noise, shape):\n",
    "    \"\"\"Samples a noise tensor according to a distribution with its gradient.\n",
    "\n",
    "  Args:\n",
    "   noise: (str) a type of supported noise distribution.\n",
    "   shape: tf.Tensor<int>, the shape of the tensor to sample.\n",
    "\n",
    "  Returns:\n",
    "   A tuple Tensor<float>[shape], Tensor<float>[shape] that corresponds to the\n",
    "   sampled noise and the gradient of log the underlying probability\n",
    "   distribution function. For instance, for a gaussian noise (normal), the\n",
    "   gradient is equal to the noise itself.\n",
    "\n",
    "  Raises:\n",
    "   ValueError in case the requested noise distribution is not supported.\n",
    "   See perturbations.SUPPORTED_NOISES for the list of supported distributions.\n",
    "  \"\"\"\n",
    "    if noise not in SUPPORTED_NOISES:\n",
    "        raise ValueError(\n",
    "            \"{} noise is not supported. Use one of [{}]\".format(\n",
    "                noise, SUPPORTED_NOISES\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if noise == _GUMBEL:\n",
    "        sampler = torch.distributions.gumbel.Gumbel(0.0, 1.0)\n",
    "        samples = sampler.sample(shape)\n",
    "        gradients = 1 - torch.exp(-samples)\n",
    "    elif noise == _NORMAL:\n",
    "        sampler = torch.distributions.normal.Normal(0.0, 1.0)\n",
    "        samples = sampler.sample(shape)\n",
    "        gradients = samples\n",
    "\n",
    "    return samples, gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn([3, 2])\n",
    "batched = True\n",
    "num_samples = 300\n",
    "sigma = 1.\n",
    "noise = _NORMAL\n",
    "batched = True\n",
    "func = lambda x: torch.nn.functional.one_hot(torch.argmax(x, 1), x.shape[1]).type(x.dtype)\n",
    "# original_input_shape = input_tensor.shape\n",
    "# if batched:\n",
    "#     assert len(original_input_shape) >= 2\n",
    "# else:\n",
    "#     input_tensor = input_tensor.unsqueeze(0)\n",
    "# input_shape = input_tensor.shape  # [B, D1, ... Dk], k >= 1\n",
    "# perturbed_input_shape = [num_samples] + list(input_shape)\n",
    "\n",
    "# noises = sample_noise_with_gradients(noise, perturbed_input_shape)\n",
    "# additive_noise, noise_gradient = [noise.type(input_tensor.dtype) for noise in noises]\n",
    "# perturbed_input = input_tensor.unsqueeze(0) + sigma * additive_noise\n",
    "\n",
    "# # [N, B, D1, ..., Dk] -> [NB, D1, ..., Dk].\n",
    "# flat_batch_dim_shape = [-1] + list(input_shape[1:])\n",
    "# perturbed_input = perturbed_input.view(flat_batch_dim_shape)\n",
    "# # Calls user-defined function in a perturbation agnostic manner.\n",
    "# perturbed_output = func(perturbed_input)\n",
    "# # [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk].\n",
    "# perturbed_input = perturbed_input.view(perturbed_input_shape)\n",
    "# # Either\n",
    "# #   (Default case): [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk]\n",
    "# # or\n",
    "# #   (Full-reduce case) [NB] -> [N, B]\n",
    "# perturbed_output_shape = [num_samples] + [-1] + list(perturbed_output.shape[1:])\n",
    "# perturbed_output = perturbed_output.view(perturbed_output_shape)\n",
    "\n",
    "# forward_output = perturbed_output.mean(0)\n",
    "# if not batched:  # Removes dummy batch dimension.\n",
    "#     forward_output = forward_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 0.0000e+00],\n",
       "        [9.9998e-01, 2.0000e-05],\n",
       "        [0.0000e+00, 1.0000e+00]], grad_fn=<PerturbedTchBackward>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched = True\n",
    "num_samples = 100000\n",
    "sigma = 0.05\n",
    "noise = _GUMBEL\n",
    "batched = True\n",
    "func = lambda x: torch.nn.functional.one_hot(torch.argmax(x, 1), x.shape[1]).type(x.dtype)\n",
    "\n",
    "class PerturbedTch(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input_tensor):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        original_input_shape = input_tensor.shape\n",
    "        orig_shape = torch.LongTensor(list(original_input_shape))\n",
    "        if batched:\n",
    "            assert len(original_input_shape) >= 2\n",
    "        else:\n",
    "            input_tensor = input_tensor.unsqueeze(0)\n",
    "        input_shape = input_tensor.shape  # [B, D1, ... Dk], k >= 1\n",
    "        perturbed_input_shape = [num_samples] + list(input_shape)\n",
    "\n",
    "        noises = sample_noise_with_gradients(noise, perturbed_input_shape)\n",
    "        additive_noise, noise_gradient = [noise.type(input_tensor.dtype) for noise in noises]\n",
    "        perturbed_input = input_tensor.unsqueeze(0) + sigma * additive_noise\n",
    "\n",
    "        # [N, B, D1, ..., Dk] -> [NB, D1, ..., Dk].\n",
    "        flat_batch_dim_shape = [-1] + list(input_shape[1:])\n",
    "        perturbed_input = perturbed_input.view(flat_batch_dim_shape)\n",
    "        # Calls user-defined function in a perturbation agnostic manner.\n",
    "        perturbed_output = func(perturbed_input)\n",
    "        # [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk].\n",
    "        perturbed_input = perturbed_input.view(perturbed_input_shape)\n",
    "        # Either\n",
    "        #   (Default case): [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk]\n",
    "        # or\n",
    "        #   (Full-reduce case) [NB] -> [N, B]\n",
    "        perturbed_output_shape = [num_samples] + [-1] + list(perturbed_output.shape[1:])\n",
    "        perturbed_output = perturbed_output.view(perturbed_output_shape)\n",
    "        \n",
    "        forward_output = perturbed_output.mean(0)\n",
    "        if not batched:  # Removes dummy batch dimension.\n",
    "            forward_output = forward_output[0]\n",
    "        ctx.save_for_backward(orig_shape, noise_gradient, perturbed_output)\n",
    "        return forward_output\n",
    "        # ctx.save_for_backward(original_input_shape)\n",
    "        # return input_tensor.clamp(min=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dy):\n",
    "        original_input_shape, noise_gradient, perturbed_output = ctx.saved_tensors\n",
    "        # perturbed_input_shape = [num_samples] if batched else [num_samples, 1] + list(original_input_shape)\n",
    "        # perturbed_input_rank = len(perturbed_input_shape)\n",
    "        perturbed_input_rank = len(original_input_shape) + (1 if batched else 2)\n",
    "\n",
    "        \"\"\"Compute the gradient of the expectation via integration by parts.\"\"\"\n",
    "        output, noise_grad = perturbed_output, noise_gradient\n",
    "        # Adds dummy feature/channel dimension internally.\n",
    "        if perturbed_input_rank > len(output.shape):\n",
    "            dy = dy.unsqueeze(-1)\n",
    "            output = output.unsqueeze(-1)\n",
    "        # Adds dummy batch dimension internally.\n",
    "        if not batched:\n",
    "            dy = dy.unsqueeze(0)\n",
    "        # Flattens [D1, ..., Dk] to a single feat dim [D].\n",
    "        flatten = lambda t: t.view(t.shape[0], t.shape[1], -1)\n",
    "        dy = dy.view(dy.shape[0], -1)  # (B, D)\n",
    "        output = flatten(output)  # (N, B, D)\n",
    "        noise_grad = flatten(noise_grad)  # (N, B, D)\n",
    "\n",
    "        g = torch.einsum(\n",
    "            \"nbd,nb->bd\",\n",
    "            noise_grad,\n",
    "            torch.einsum(\"nbd,bd->nb\", output, dy),\n",
    "        )\n",
    "        g /= sigma * num_samples\n",
    "        return g.view(*original_input_shape)\n",
    "\n",
    "input_tensor = torch.randn([3, 2])\n",
    "input_tensor.requires_grad = True\n",
    "out = PerturbedTch.apply(input_tensor)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = out.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0183, -0.0135],\n",
       "        [-0.0087,  0.0170],\n",
       "        [-0.0156,  0.0078]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8010,  1.2944,  0.4856,  0.6414,  0.1016],\n",
      "         [-0.1898,  0.3584,  0.4202, -0.8507, -0.2613],\n",
      "         [ 1.1522, -1.0642,  1.1020,  0.9677,  0.4820]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from perturbations.fenchel_young_tch import FenchelYoungLoss\n",
    "\n",
    "def ranks(inputs, dim=-1):\n",
    "    \"\"\"Returns the ranks of the input values among the given axis.\"\"\"\n",
    "    return 1 + inputs.argsort(dim).argsort(dim).type(inputs.dtype)\n",
    "\n",
    "x = torch.randn([3, 5]).float().unsqueeze(0)\n",
    "print(x)\n",
    "x.requires_grad = True\n",
    "y_true = torch.arange(5).float().unsqueeze(0).repeat([x.shape[0], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD([x], 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.7310, -0.3490, -0.3152, -0.2833, -0.2496],\n",
       "         [-1.3052, -1.0426, -1.0086, -0.9748, -0.8419],\n",
       "         [-0.9017, -1.0642, -0.0498, -0.0148,  0.0202]]], requires_grad=True)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim.zero_grad()\n",
    "criterion = FenchelYoungLoss(ranks)\n",
    "loss = criterion(y_true, x).sum()\n",
    "loss.backward()\n",
    "optim.step()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "f = criterion.perturbed(x)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
